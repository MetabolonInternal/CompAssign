# RT + Sally realtest follow-ups

Baseline: `COMPASSIGN_PP_RIDGE` with `mixture_model` coherence filter (see `docs/models/rt_pymc_multilevel_pooling_report.tex`).

## Next required (production readiness)

- [ ] Standardize ontology for species/matrix grouping in RT training data so it matches production usage:
  align SMT / `species_cluster` terms and the semantics of `species` across lib208 and lib209 (they currently derive from
  different input columns), and make the training/data-prep pipeline emit canonical fields that can be applied to new
  production data without schema-specific hacks.

  Current state (what is inconsistent today):
  - The mapping CSV used to build production RT CSVs is generated by
    `src/compassign/rt/data_prep/check_rt_metadata_mapping.py`.
  - That script defines `species_raw` differently by library:
    - lib209: `species_raw := species_matrix_type` from `data/split_outputs/data/_lib_209_input.csv`
      (examples: `human_plasma`, `rat_urine`, `mus_musculus_c57bl/6j_plasma`).
    - lib208: `species_raw := JCJ_COMBO` from `data/split_outputs/data/_lib_208_input.csv`
      (examples: `PLASMA+UNKNOWN COAGULANT+HUMAN+HOMO SAPIENS`, `TISSUE+LIVER+RODENT+RAT`).
    This means the numeric `species` ids in training do not represent the same ontology across libs.
  - `species_cluster` currently comes from the `group` column in both input CSVs and is intended to be a stable
    supercategory label (e.g. `1 human blood`, `5 mammal tissue`). However, lib209 has many empty `group` values (405
    rows in the current `_lib_209_input.csv`), and `check_rt_metadata_mapping.py` drops rows with missing group.
    Since the production ontology table provides `Supercategory`, a better long-term approach is to ignore `group` when it
    is missing and instead infer `species_cluster` by mapping the sample-set SMT to `Supercategory` using the PHNX-ONT
    expansion table.

  Evidence / quick stats (from the current split input CSVs):
  - `_lib_208_input.csv`: 89 unique `JCJ_COMBO` values; 7 non-empty `group` values.
  - `_lib_209_input.csv`: 240 unique `species_matrix_type` values; 7 non-empty `group` values (plus many empty).
  The larger number of unique SMTs in lib209 likely fragments training support more than lib208 (potentially reducing
  mean-prediction gains, even when uncertainty calibration improves).
  - Offline regression (from the report Table "Global held-out test metrics"):
    - lib208 RMSE improves 0.009050 → 0.007846 (supercategory ridge → partial pooling).
    - lib209 RMSE improves 0.008295 → 0.007589, but the larger benefit is calibration (Cov95 0.919 → 0.957).
    This suggests lib209 is already closer to the irreducible error floor in mean prediction, and the hierarchy helps
    most by fixing under-coverage.

  Why this matters:
  - The production RT CSV loader (`src/compassign/rt/prod_csv_loader.py`) expects numeric `species` and
    `species_cluster` already in the CSV. If our training encoding is not derived from a production-derivable ontology,
    we cannot reliably score new production data (or we will need brittle per-schema hacks).
  - The current mapping generator drops rows with missing `group` when creating the encoded mapping. We should explicitly
    confirm that the resulting mapping still covers all `sample_set_id` values present in the merged-training Parquet for
    each lib; otherwise production CSV generation will fail at join time.

  Target state (proposed):
  - Define a canonical SMT string key (call it `smt_raw`) that production can compute for any SSID, and use it as the
    meaning of `species` for *both* lib208 and lib209.
  - Define a canonical supercategory key (call it `supercat_raw`) that production can compute (or at least look up) and
    use it as the meaning of `species_cluster`.
  - Use the production SMT ontology as the source of truth for *codes* (not just names). The current mapping generator
    assigns integer ids by enumerating observed values; this is not stable and cannot be guaranteed to match production.
    The intended end state is that `species` and `species_cluster` in the RT production CSV use the same numeric ids as
    production.
  - Production SMT ontology reference (internal) is PHNX-ONT:
    - Repo snapshot: `resources/phoenix_ontology/PHNX-ONT_Approved_Ontology_List_blank_copy_id_13010976.pdf`
    - Production-derived expanded table (used by production normalization; includes `Phoenix Ontology` and `Supercategory`
      columns): `resources/phoenix_ontology/expanded_dcent_table.csv`
      (copied from `/Users/joewandy/Work/MetabolonInternal/normalizationService/normalizationCli/data/expanded_dcent_table.csv`).

  Proposed implementation steps (next session):
  - Treat `resources/phoenix_ontology/expanded_dcent_table.csv` as the canonical machine-readable ontology source:
    - `Phoenix Ontology` is the canonical SMT key in production (string, can be used as an ID).
    - `Supercategory` is the canonical supercategory key in production (string, can be used as an ID).
    - Columns `Matrix`, `Matrix Type`, `Organism`, `Species` provide the four-term decomposition used to form
      `Phoenix Ontology`.
    - `Supercategory` strings appear to be a normalized form of the training `group` label (e.g. `1 human blood` maps to
      `supercategory_1_human_blood`). This can likely be used as a deterministic bridge when `group` is present.
    - If we decide `species` should be coarser than `Phoenix Ontology`, a production-consistent alternative is to derive
      a key that drops `Matrix Type`, e.g. `smt_coarse := <Species>_<Matrix>` (lowercased), which matches existing
      `species_matrix_type` strings in lib209 training metadata (e.g. `Human`+`Plasma` → `human_plasma`).
    If additional tables are needed, regenerate a CSV export from PHNX-ONT (prefer an upstream export over PDF scraping).
  - Decide which fields in production generate SMT and supercategory; document the exact canonicalization rules
    (string normalization and any allowed collapses).
  - Build a deterministic mapping from SMT → Supercategory using the expanded table and use it to fill missing
    `group`/`species_cluster` values in lib209 (and validate uniqueness: each SMT should map to exactly one
    Supercategory).
  - Confirm which production fields define SMT (likely closest to `species_matrix_type` semantics).
  - Implement a deterministic normalizer for lib209 `species_matrix_type` (case/spacing, and optionally a controlled
    collapse of overly-specific strings like strain names if production SMT is coarser).
  - Implement a deterministic mapper for lib208 based on available columns (`JCJ MATRIX`, `JCJ MATRIX TYPE`,
    `JCJ SPECIES`/`JCJ ORGANISM`) to produce the same canonical `smt_raw` vocabulary used for lib209.
  - Update `check_rt_metadata_mapping.py` to emit `sample_set_id, smt_raw, supercat_raw, species, species_cluster` and
    make downstream data-prep scripts consume those canonical columns.
  - Validate by rebuilding RT production CSVs, retraining, and rerunning `./src/compassign/rt/sally_test.sh` to ensure
    TS tables remain stable.

- [ ] Expand evaluation across more SSIDs (and multi-library sample sets) to confirm robustness under different run
  conditions and post-processing settings.

## Optional improvements (only if we still need more TS)
- [ ] Pursue cloud/mode coherence (select a coherent residual mode across tasks and re-score or rescue per-task picks,
  rather than treating tasks independently).

## Repro commands
- Train CompAssign RT models: `conda activate compassign && ./src/compassign/rt/train.sh`
- Run Sally evaluations: `conda activate sally && ./src/compassign/rt/sally_test.sh`
